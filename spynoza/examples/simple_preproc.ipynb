{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple fMRI preprocessing pipeline\n",
    "This notebook describes a simple preprocessing pipeline for fMRI data, using the [nipype](http://nipy.org/nipype/) environment/package (Gorgolewski K., et al., 2011, Front. Neurinform. 5:13), in which a combination of FSL-software and custom Python scripts are used. \n",
    "\n",
    "Lukas Snoek, University of Amsterdam (lukassnoek@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages and settings\n",
    "Below, necessary packages are imported and some pipeline-specific variables are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "import os\n",
    "import os.path as op\n",
    "import glob\n",
    "import nipype\n",
    "import matplotlib.pyplot as plt\n",
    "import nipype.interfaces.fsl as fsl\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.utility as util\n",
    "import nibabel as nib\n",
    "from IPython.display import Image\n",
    "from nipype.interfaces.utility import IdentityInterface\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from IPython.display import Image\n",
    "\n",
    "# Importing of custom nodes from spynoza packages; assumes that spynoza is installed:\n",
    "# pip install git+https://github.com/spinoza-centre/spynoza.git@master\n",
    "from spynoza.nodes import apply_sg_filter, find_middle_run, get_scaninfo\n",
    "from spynoza.BIDS_tools import BIDSConstructor, fetch_example_data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the project structure\n",
    "To use Nipype effectively, it's nice to have your data structured in a way such that it is easy to glob\n",
    "files. Here, a custom class (DataOrganizer) is used to set up a project structure/skeleton and to\n",
    "perform some minor preprocessing (PAR/REC conversion). After initializing the DataOrganizer, you can download the data using the `fetch_test_data` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project_dir = op.join(os.path.expanduser('~'), 'nipype_example')\n",
    "data_dir = op.join(project_dir, 'sample_data_bids')\n",
    "run_names = {'func': ['hww', 'zinnen1', 'zinnen2'],\n",
    "             'anat': 'T1'}\n",
    "\n",
    "config_file = op.join(data_dir, 'config.json')\n",
    "data_organizer = BIDSConstructor(data_dir, config_file) \n",
    "print('Data will be processed in: \\n%s' % project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the pipeline described below, you can download some example data from my dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#_ = fetch_example_data(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The method-calls below set up the project structure.\n",
    "#data_organizer.reset_pipeline() # only for testing purposes\n",
    "data_organizer.convert2bids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the workflow\n",
    "Definition of nodes within pipeline + inputs (infosource / selectfiles) + outputs (datasink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# i/o\n",
    "subject_list = [op.basename(f) for f in data_organizer.sub_dirs] # we'll iterate over this list!\n",
    "derivatives_dir = op.join(project_dir, 'derivatives')\n",
    "datasink_name = 'datasink_preprocessing'        \n",
    "\n",
    "# Analysis parameters\n",
    "frac_T1 = 0.4\n",
    "frac_epi = 0.2\n",
    "robust_bet = True\n",
    "fwhm = 5.0\n",
    "mcflt_cost = 'mutualinfo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input/output nodes\n",
    "First, the input nodes (infosource / selectfiles) and output nodes (datasink) are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Infosource simply distributes iterables (here: subjects) for parallel processing\n",
    "infosource = pe.Node(IdentityInterface(fields=['subject_id']), name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list)]\n",
    "# you can also specify other iterables, such as models or runs \n",
    "\n",
    "# The template is used to glob files\n",
    "template = {\n",
    "    'func': op.join(data_dir, '{subject_id}', 'func', '*.nii.gz'),\n",
    "    'anat': op.join(data_dir, '{subject_id}', 'anat', '*.nii.gz'),\n",
    "    'log': op.join(data_dir, '{subject_id}', 'func', '*.log')}\n",
    "\n",
    "selectfiles = pe.Node(SelectFiles(template, base_directory=data_dir), name=\"selectfiles\")\n",
    "\n",
    "datasink = pe.Node(DataSink(base_directory=derivatives_dir, container=datasink_name), name=\"datasink\")\n",
    "substitutions = [('_subject_id_', '')]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T1 processing stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reorient_T1 = pe.Node(interface=fsl.Reorient2Std(), name='reorient_T1')\n",
    "bet_T1 = pe.Node(interface=fsl.BET(frac=frac_T1, robust=robust_bet), name='bet_T1')\n",
    "fast = pe.Node(interface=fsl.FAST(), name='segment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPI processing stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reorient_epi = pe.MapNode(interface=fsl.Reorient2Std(), name='reorient_epi', iterfield='in_file')\n",
    "bet_epi = pe.MapNode(interface=fsl.BET(frac=frac_epi, functional=True), name='bet_epi', iterfield='in_file')\n",
    "\n",
    "findmiddlerun = pe.Node(util.Function(input_names=['in_files'],\n",
    "                                           output_names=['middle_run', 'other_runs'],\n",
    "                                           function=find_middle_run),\n",
    "                        name='find_middle_run')\n",
    "\n",
    "mean_bold = pe.Node(interface=fsl.maths.MeanImage(dimension='T'), name='mean_bold')\n",
    "\n",
    "# Note that the mcflirt-node for the middle run is a Node and the mcflirt-node for the rest of the runs is\n",
    "# a MapNode (because it takes in a list of files).\n",
    "mcflirt_middle = pe.Node(interface=fsl.MCFLIRT(cost=mcflt_cost, interpolation='sinc', stages=3, save_plots=True),\n",
    "                            name='mcflirt_middle')\n",
    "\n",
    "mcflirt_rest = pe.MapNode(interface=fsl.MCFLIRT(cost=mcflt_cost, interpolation='sinc', stages=3, save_plots=True),\n",
    "                       name='mcflirt_rest', iterfield='in_file')\n",
    "\n",
    "plot_motion = pe.MapNode(interface=fsl.PlotMotionParams(in_source='fsl'),\n",
    "                        name='plot_motion',\n",
    "                        iterfield=['in_file'])\n",
    "\n",
    "# Iterate over rotations and translations!\n",
    "plot_motion.iterables = ('plot_type', ['rotations', 'translations'])\n",
    "\n",
    "slicetimer = pe.MapNode(interface=fsl.SliceTimer(interleaved=False), \n",
    "                        name='slicetimer', \n",
    "                        iterfield=['in_file', 'time_repetition'])\n",
    "\n",
    "smooth = pe.MapNode(interface=fsl.IsotropicSmooth(fwhm=fwhm), \n",
    "                    name='smooth', iterfield=['in_file'])\n",
    "\n",
    "sgfilter = pe.MapNode(util.Function(input_names=['in_file'],\n",
    "                                    output_names=['out_file'],\n",
    "                                    function=apply_sg_filter),\n",
    "                      iterfield=['in_file'],\n",
    "                      name='sgfilter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc. nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extract_scaninfo = pe.MapNode(util.Function(input_names=['in_file'],\n",
    "                                        output_names=['TR', 'shape', 'dyns', 'voxsize', 'affine'],\n",
    "                                        function=get_scaninfo),\n",
    "                          name='extract_scaninfo',\n",
    "                          iterfield='in_file')\n",
    "\n",
    "# These files merge inputs from different nodes in a list to be used by downstream MapNodes.\n",
    "mcflirt_merger_infiles = pe.Node(interface=util.Merge(2), name='mcflirt_merger_infiles')\n",
    "mcflirt_merger_motionplots = pe.Node(interface=util.Merge(2), name='mcflirt_merger_motionplots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect nodes together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc = pe.Workflow(name='preproc')\n",
    "preproc.base_dir = derivatives_dir\n",
    "preproc.connect(infosource, 'subject_id', selectfiles, 'subject_id')\n",
    "\n",
    "preproc.connect(selectfiles, 'anat', reorient_T1, 'in_file')\n",
    "preproc.connect(reorient_T1, 'out_file', bet_T1, 'in_file')\n",
    "preproc.connect(bet_T1, 'out_file', datasink, 'bett1')\n",
    "preproc.connect(bet_T1, 'out_file', fast, 'in_files')\n",
    "preproc.connect(fast, 'tissue_class_files', datasink, 'fast')\n",
    "\n",
    "preproc.connect(selectfiles, 'func', reorient_epi, 'in_file')\n",
    "preproc.connect(reorient_epi, 'out_file', bet_epi, 'in_file')\n",
    "\n",
    "preproc.connect(bet_epi, 'out_file', findmiddlerun, 'in_files')\n",
    "preproc.connect(findmiddlerun, 'middle_run', mcflirt_middle, 'in_file')\n",
    "preproc.connect(mcflirt_middle, 'out_file', mean_bold, 'in_file')\n",
    "preproc.connect(mean_bold, 'out_file', mcflirt_rest, 'ref_file')\n",
    "preproc.connect(findmiddlerun, 'other_runs', mcflirt_rest, 'in_file')\n",
    "preproc.connect(mcflirt_middle, 'out_file', mcflirt_merger_infiles, 'in1')\n",
    "preproc.connect(mcflirt_rest, 'out_file', mcflirt_merger_infiles, 'in2')\n",
    "preproc.connect(mcflirt_merger_infiles, 'out', slicetimer, 'in_file')\n",
    "\n",
    "preproc.connect(mcflirt_middle, 'par_file', mcflirt_merger_motionplots, 'in1')\n",
    "preproc.connect(mcflirt_rest, 'par_file', mcflirt_merger_motionplots, 'in2')\n",
    "preproc.connect(mcflirt_merger_motionplots, 'out', plot_motion, 'in_file')\n",
    "preproc.connect(plot_motion, 'out_file', datasink, 'mcplots')\n",
    "preproc.connect(mean_bold, 'out_file', datasink, 'meanbold')\n",
    "\n",
    "preproc.connect(slicetimer, 'slice_time_corrected_file', smooth, 'in_file')\n",
    "preproc.connect(smooth, 'out_file', sgfilter, 'in_file')\n",
    "preproc.connect(selectfiles, 'func', extract_scaninfo, 'in_file')\n",
    "preproc.connect(extract_scaninfo, 'TR', slicetimer, 'time_repetition')\n",
    "\n",
    "preproc.connect(sgfilter, 'out_file', datasink, 'fullypreproc')\n",
    "\n",
    "preproc.write_graph()\n",
    "Image(filename=op.join(derivatives_dir, preproc.name, 'graph.dot.png'))\n",
    "\n",
    "# Check out a more detailed graph by:\n",
    "#Image(filename=os.path.join(data_organizer.project_dir, preproc.name, 'graph_detailed.dot.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run workflow!\n",
    "preproc.config = {'execution' : {'stop_on_first_crash' : True,\n",
    "                                 'keep_inputs': True,\n",
    "                                 'remove_unnecessary_outputs': True}}\n",
    "graph = preproc.run('MultiProc', plugin_args={'n_procs': 5})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
